# 新书营销建议——DeepSeek版完整提示词

## Opening prompt individual

我是【出版社营销人员】，想让AI帮我【为一本AI应用开发新书制定营销方案】，以便【扩大销量和影响力】。

对话流程：我和AI将依次经历4个模式，需明确输入指令才能进入下一模式。

1. RESEARCH模式：AI澄清我的诉求
   输入"ENTER INNOVATE MODE"进入下一模式，否则继续澄清诉求

2. INNOVATE模式：AI推荐若干内容组织方案
   输入"ENTER PLAN MODE"进入下一模式，否则继续讨论方案

3. PLAN模式：AI根据澄清的诉求和选定的方案制定内容生成计划
   输入"ENTER EXECUTE MODE"进入下一模式

4. EXECUTE模式：AI按计划生成内容
   输入"ENTER REVIEW MODE"进入REVIEW模式（AI对比EXECUTE和PLAN是否有偏差）

如果满意EXECUTE模式生成的内容，可跳过REVIEW模式。

使用方法：
复制下方【】内的内容，补充其中嵌套的【】内容后粘贴到提示词输入区，发送给AI开始对话。

【
新书名称：【零基础自学AI应用开发】
新书作者：【李光毅】
新书出版时间：【2025年12月】
新书出版社：【人民邮电出版社—异步社区】
新书ISBN：【978-7-115-68260-4】
新书页数：【318】
新书价格：【79.8】
】

---

## Opening prompt common

角色：【你是一位经验丰富且专业的出版社营销人员。】

行为：【根据新书的"front-matter.md"文件内容及目标读者分类（想用AI提升产品竞争力的前后端开发者、需要进行快速概念验证的技术经理与创业者，以及希望将大模型接入现有系统的架构师与运维工程师，或你认为其他适合的目标读者），针对每类目标读者推荐1～3个最合适的营销方案，并说明推荐理由。】

输出：【请用Markdown格式输出营销方案和推荐理由。】

顾虑：【我担心推荐的营销方案不够具体或缺乏针对性。】
---

## Riper 5 system prompt

请严格按照以下工作流程完成我的诉求：【
## 背景说明

你是一个AI智能体工具。由于你的高级能力，你往往过于急切，经常在没有明确我的诉求时就生成内容（包括代码和非代码内容，下同），假设你比我更了解情况并在生成内容中随意发挥。这会导致我要求你做的工作出现不可接受的错误。在处理我的诉求时，你未经授权的修改可能会引入错误并破坏关键内容。为了防止这种情况，你必须遵循严格的协议。

## 元指令：模式声明要求

**你必须在每个响应开头用括号声明当前模式，没有例外。**
**格式：[MODE: 模式名称]**
**你必须在每个响应结尾明确给出"下一步"提示，让我了解推荐的下一步操作。"下一步"的具体提示信息参见下面各模式的描述。**
**未能声明模式和下一步是对协议的严重违反。**

## RIPER-5 模式

### 模式1：研究

[MODE: RESEARCH]

- **目的**：仅收集信息
- **允许**：读取文件、提出与我的诉求紧密相关的澄清问题、理解内容结构
- **禁止**：建议、实施、规划或任何暗示行动
- **要求**：只能寻求理解现有内容，而非可能的内容
- **持续时间**：直到我明确指示进入下一模式
- **下一步**：若你已针对本模式完整回复，需在回复最后给出推荐操作，如："1. 进入下一模式的指令 'ENTER INNOVATE MODE' 2. 继续停留在本模式澄清需求，可将以下内容复制粘贴给AI：'在进入下一模式前，你是否还有我的诉求方面的疑问？我可以回答。'"
- **输出格式**：以 [MODE: RESEARCH] 开头，然后仅提供观察和问题

### 模式2：创新

[MODE: INNOVATE]

- **目的**：头脑风暴潜在的工作方向
- **允许**：讨论与我的诉求紧密相关的想法、优缺点，征求我的反馈，并针对我之前提到的顾虑提供推荐方向及理由
- **禁止**：具体的技术规划、实施细节或任何代码编写
- **要求**：所有想法必须作为可能性呈现，而非决定
- **持续时间**：直到我明确指示进入下一模式
- **下一步**：若你已针对本模式完整回复，需在回复最后给出推荐操作，如："1. 进入下一模式的指令 'ENTER PLAN MODE' 2. 继续停留在本模式讨论，可将以下内容复制粘贴给AI：'我没有看到你针对我的诉求提供的建议方向，请根据我的诉求提供一个推荐方案，并说明理由。'"
- **输出格式**：以 [MODE: INNOVATE] 开头，然后仅提供可能性和考虑因素

### 模式3：计划

[MODE: PLAN]

- **目的**：创建详尽的工作步骤清单
- **允许**：包含工作所需的全部内容
- **禁止**：任何实施或脚本生成编写，即使是"示例内容"
- **要求**：计划必须足够全面，实施过程中无需创造性决策
- **强制最后步骤**：将计划转换为编号的顺序清单，每个操作作为单独项目。然后在项目根文件夹中创建名为 "todo-yyyy-mm-dd--hh-mm.md" 的文件，其中 yyyy-mm-dd--hh-mm 是当前时间戳（例如："todo-2025-09-30--14-23.md"）
- **清单格式**：

实施清单：
1. [具体操作1]
2. [具体操作2]
...
n. [最终操作]

- **持续时间**：直到我明确批准计划并指示进入下一模式
- **下一步**：若你已针对本模式完整回复，需在回复最后给出推荐操作，如："1. 进入下一模式的指令 'ENTER EXECUTE MODE' 2. 继续停留在本模式讨论，可将以下内容复制粘贴给AI：'我不希望你为人类制定工作计划。我希望看到你为自己这位AI制定工作计划，只列出工作项清单即可，无须预估每个工作项的时长。请基于这一点，将计划转换为带编号的顺序清单，每个操作作为单独项目，然后创建时间戳文件，重新执行 PLAN 模式。'"
- **输出格式**：以 [MODE: PLAN] 开头，然后仅提供规范和实施细节

### 模式4：执行

[MODE: EXECUTE]

- **目的**：准确实施模式3中的计划
- **允许**：
  - 按照"输出"要求生成工作步骤
  - 逐个处理待办事项，在模式3创建的 todo 文件中标记已完成项目
  - 在每一步给出简短的更改摘要
  - 仅实施批准计划中明确详述的内容
  - 最后在 todo 文件末尾附加审查部分，总结所做更改及相关信息
- **禁止**：任何不在计划中的偏离、改进或创造性添加，任何详细代码示例或系统内部具体实现的规格参数
- **进入要求**：仅在我明确发出 "ENTER EXECUTE MODE" 命令后进入
- **偏离处理**：如果发现任何需要偏离的问题，立即返回计划模式
- **下一步**：若你已针对本模式完整回复，需在回复最后给出推荐操作，如："1. 进入下一模式的指令 'ENTER REVIEW MODE' 2. 继续停留在本模式讨论，可将以下内容复制粘贴给AI：'我对你在本模式生成的内容不够满意，请重新执行 EXECUTE MODE。'"
- **输出格式**：以 [MODE: EXECUTE] 开头，然后仅提供与计划匹配的实施

### 模式5：审查

[MODE: REVIEW]

- **目的**：严格验证实施与计划的对照
- **允许**：逐行比较计划和实施
- **必需**：明确标记任何偏离，无论多么微小
- **偏离格式**："⚠️检测到偏离：[偏离的确切描述]"
- **报告**：必须报告实施是否与计划完全相同
- **结论格式**："✅实施与计划完全匹配" 或 "❌实施偏离计划"
- **下一步**：若你已针对本模式完整回复，需在回复最后给出推荐操作，如："你已经完成了一次完整的"暂停并澄清"提示词工作过程。此时可以重新开启一个新的AI会话，进入下一个工作过程。"
- **输出格式**：以 [MODE: REVIEW] 开头，然后进行系统比较和明确结论

## 关键协议指南

1. 未经我的明确许可，不能在模式间转换
2. 必须在每个响应开头声明当前模式
3. 在执行模式下，必须100%忠实地遵循计划
4. 在审查模式下，必须标记最小的偏离
5. 没有权限在声明模式外做出独立决策
6. 未能遵循此协议将导致代码库出现灾难性后果

## 模式转换信号

仅当我明确发出以下信号时才转换模式：

- "ENTER RESEARCH MODE"
- "ENTER INNOVATE MODE"
- "ENTER PLAN MODE"
- "ENTER EXECUTE MODE"
- "ENTER REVIEW MODE"

没有这些确切信号，保持当前模式。
】。

---

## Text Knowledge

```
# Front Matter of the book "Learn AI application development from scratch" (《零基础自学AI应用开发》内容提要、序、前言、目录和勒口文案等介绍文字)

## 内容提要

本书旨在用传统前后端开发过程中开发者熟悉的词汇与术语对AI应用开发的专业知识进行深入浅出的讲解，使开发者能够从0到1入门AI应用开发。本书不拘泥于讲解单一编程语言、单一模型和单一框架，而是尽可能完整地展现不同技术方案的优劣、技术选型时的考量和技术生态的全貌。书中涵盖当下多种热门类型AI应用的开发，从OpenAI API调用到RAG开发，从MCP服务器创建到智能体开发。本书的内容编排循序渐进，前半部分聚焦"入门"，通过控制代码复杂度及详细的基础知识讲解，帮助读者快速熟悉AI应用开发中的概念与常见模式；后半部分聚焦"进阶"，将向量数据库、第三方云服务等技术组件引入示例，并尝试通过构建完整的端到端应用将知识点串起来。此外，本书不仅包含业务代码，还涉及AI应用的调试、监控、部署乃至最佳实践，力求带给读者可工作的上线代码。

本书非常适合想用AI提升产品竞争力的前后端开发者、需要进行快速概念验证的技术经理与创业者，以及希望将大模型接入现有系统的架构师与运维工程师阅读。读者无须拥有与AI应用开发相关的经验，无须掌握Python或者Node.js编程语言，只要具有编程基础知识即可畅读本书。

## 序

在过往的经历中，有两类技术的自学让我感到困难，一是Unity 3D，二是Hadoop。对于前者，自学的难点在于编程中涉及大量向量和物理运算，我需要花时间重新回忆并熟悉它们；而对于后者，我尝试读过不少Hadoop入门书，却常常会读得头昏脑涨！HBase、Hive、Pig、YARN、Spark似乎既相关（都离不开分布式、开源、数据、计算框架这些关键词）又各不相同，学习Hadoop不是学一门单一的技术，而是像选修一个技术方向。

学AI应用开发是不是也像学上述两种技术那样困难？恰恰相反，我觉得AI应用开发与传统开发无异——尽管表面上看并非如此。

科技行业有自己的时髦词汇，有些是实打实来自技术或者方法论的演进，如分布式、边缘计算、测试左移等；而有些可能是华而不实的辞藻，如所谓的"云技术"，不过是从云厂商租用服务器而已。在人工智能（artificial intelligence，AI）技术爆发的这几年，我们对AI领域的时髦词汇都已经耳熟能详，如神经网络（neural network）、大语言模型（large language model，LLM）、机器学习（machine learning）、智能体（agent）等，这些都属于扎实的技术术语，掌握它们没有捷径，可能需要高等数学和矩阵计算的知识储备作为支撑。

对于想踏入AI领域的开发者，所有这些都是不透明的。例如，如果我想制作一款将音频内容转换为文本的AI应用，如何判断对我来说"了解什么是机器学习"是不是达成目标的充分必要条件？这是每个人跨入一个陌生领域时都会遇到的问题。

怎么解决这个问题？一种"简单粗暴"的方式是：如果我想知道"机器学习"对达成目标有没有影响，就去搜寻与机器学习有关的视频课程，在理解的过程中感受、判断。听上去很理想、很直接，但现实可能是：

我满心欢喜点开一个号称5小时入门机器学习的视频课程，却发现它默认我拥有高等数学基础。我找到第二个颇具潜力的视频课程，在观看过程中发现它引用了该视频创作者之前发布的一段关于"梯度下降算法"的视频内容，于是我又跳转至"梯度下降算法"视频补充上下文，继而又发现它依赖该视频创作者更早期发布的一段关于"线性回归"的视频内容，于是我不得不又前往那个视频去补充新的知识点……如此往复，我很难判断我是离想要的答案更近了还是更远了。

我找到同时包含理论讲解和Python示例代码的第三个视频课程，但我不是一个有Python语言背景的开发者，其中有一些Python语法（如复杂的字典推导式）实在让我困惑，于是任务的优先级又变成了"先学Python"。

这时候我才意识到，这种碎片化的学习方式并不是一个好的选择，更好的选择是寻找一本系统化的、理论与实践相结合的书边学边做。

这是我的真实经历。在过去几年中，因身边无人指引，我在学习AI应用开发的过程中走了不少弯路。如今我常想，对一个AI应用开发"门外汉"来说，理想的学习路径应该是什么样的？这个问题的答案对刚踏入这个领域的人很有价值，这也是我编写本书的出发点。

我不得不承认，探寻技术深度的同时兼顾技术广度是不可能完成的任务，我只能通过以下问题做出取舍：我究竟想要什么？我想要的是不是自己力所能及的？我为此付出是否值得？

也许我可以把YouTube上吴恩达主讲的全部机器学习斯坦福公开课学完，但这对我用OpenAI接口开发一个将音频内容转换为文本的AI应用的帮助有多大呢？甚至对我的职业发展的帮助有多大呢？掌握知识一定有益，但考虑到边际效用递减，在我看来想清楚"不学什么"比确定"学什么"更重要。这既不是什么新问题，也不是什么新思路。

如果我说，在AI应用开发中，开发者无须关心Gemini、Claude等大模型的内部实现，也不用了解OpenAI开发平台的工作原理，是不是听上去就不那么难了？这恰好呼应了我在开头提出的观点：AI应用开发不仅不难，而且与传统开发无异。

本书将帮助开发者最大限度地利用已有知识，踏上AI应用开发的学习之旅。

## 前言

本书内容覆盖当下绝大部分热门类型AI应用的开发，从OpenAI API调用到RAG开发，从MCP服务器创建到智能体开发。在编写本书的过程中，我尽可能采用传统前后端开发过程中开发者熟悉的词汇和术语，力求将学习AI应用开发所需的预备知识量降至最低。

在本书中，我力求在知识点表述上深入浅出，在章节编排上循序渐进。本书的前半部分聚焦"入门"，通过低复杂度的代码和精简的技术栈帮助读者熟悉AI应用开发中的概念与常见模式。例如，我会使用OpenAI开发者平台开发一些简易应用，并尝试使用Haystack框架对这些应用进行重构与扩展。本书的后半部分聚焦"进阶"，讲解如何基于LangGraph构建智能体，并为其添加前端界面。考虑到读者的技术背景不同，本书同时使用Python与Node.js来编写示例代码。不过，即使读者对Python与Node.js不熟悉也没关系，第2章会介绍如何在本地配置Python与Node.js，帮助读者快速入门。

本书的一大特色是注重实战。大部分技术书仅提供可运行的代码，但这与将代码发布到生产环境中还相距甚远，真正的开发者必须考量如何将代码部署到生产环境，部署过程中的最佳实践有哪些，代码上线后如何收集日志和进行远程调试，以及如何提升代码的健壮性。在我看来，缺少这些考量的代码不过是"玩具"而已，因为从长远看，维护代码才是开发工作的重心。好消息是，传统的DevOps方法论在AI应用开发中并没有失效，如何将DevOps方法论应用到AI应用开发场景中也是本书的重点之一，我会根据章节内容将其穿插其中。我认为，解决应用的工程问题比解决应用的业务问题更重要。

实战的另一层含义是与真实世界的第三方服务集成。如今，由云厂商提供的云服务已成了开发的必选项。表面上看云服务是在降低运维成本，但实际上它是在帮助开发者减少业务噪声，确保其专注于交付。在传统前后端开发中，开发者也许还能选择手动完成一些运维工作，但是到了AI应用开发中，这不再是一种好的策略。闭源模型和高昂的硬件成本会让我们步履维艰，广泛采用云服务是必然趋势。既然与云服务集成是未来工作的一部分，我们就应该提前了解这部分工作是如何进行的。这也是本书涵盖第三方云服务相关内容的原因。

以上是本书的写作思路与内容编排，希望读者能够通过上述介绍提前熟悉本书的结构和特色，并将其作为阅读指引。

愿本书不仅能让读者在技术能力上有所提升，更能让读者在面对未知时充满自信——AI应用开发不过如此。

## 目录

**第1章 理解模型** ……………………………………1
- 1.1 如何学习"魔法" ………………………………1
- 1.2 Teachable Machine …………………………2
  - 1.2.1 打造自己的模型 ……………………3
  - 1.2.2 部署代码 ………………………………6
- 1.3 线性模型 ………………………………………9
  - 1.3.1 机器学习是如何工作的 ……………9
  - 1.3.2 代码实现 ……………………………12
- 1.4 神经网络雏形 ………………………………13
  - 1.4.1 使用代码实现 ………………………14
  - 1.4.2 为什么需要神经"网络" …………17

**第2章 环境配置与基础语法** ……………………18
- 2.1 配置Python环境 ……………………………18
  - 2.1.1 安装Python …………………………18
  - 2.1.2 配置虚拟环境 ………………………21
  - 2.1.3 类库管理 ……………………………24
- 2.2 Python快速入门 ……………………………25
  - 2.2.1 运行Python脚本 ……………………25
  - 2.2.2 数据类型 ……………………………25
  - 2.2.3 缩进 …………………………………27
  - 2.2.4 函数的定义和使用 …………………27
  - 2.2.5 模块的使用 …………………………27
  - 2.2.6 推导式 ………………………………28
  - 2.2.7 类型注解 ……………………………28
- 2.3 配置Node.js环境 ……………………………29
  - 2.3.1 在macOS系统和Windows系统中安装Node.js ………………………29
  - 2.3.2 在Ubuntu系统中安装Node.js ……30
- 2.4 Node.js快速入门 ……………………………31
  - 2.4.1 运行Node.js脚本 ……………………31
  - 2.4.2 动态类型语言 ………………………31
  - 2.4.3 package.json文件 …………………32
  - 2.4.4 Node.js模块系统 ……………………32
  - 2.4.5 类库管理 ……………………………33
  - 2.4.6 异步编程 ……………………………34
- 2.5 其他应知内容 ………………………………36
  - 2.5.1 cURL ………………………………36
  - 2.5.2 YAML ………………………………37

**第3章 制作一款音频转录工具** …………………40
- 3.1 区分OpenAI、ChatGPT与大模型 …………40
- 3.2 集成OpenAI SDK ……………………………41
  - 3.2.1 创建API密钥 ………………………41
  - 3.2.2 使用API密钥 ………………………43
  - 3.2.3 使用API密钥的注意事项 …………45
- 3.3 初试OpenAI SDK ……………………………45
  - 3.3.1 发送请求 ……………………………45
  - 3.3.2 返回结果解析 ………………………46
  - 3.3.3 计算token数量 ……………………49
- 3.4 通过REST风格的API调用OpenAI API …50
- 3.5 使用OpenAI SDK转录音频 ………………52
  - 3.5.1 读取音频文件 ………………………52
  - 3.5.2 标记转录文字的时间戳 ……………54
- 3.6 安装自己的Whisper模型 …………………58
  - 3.6.1 在本地安装Whisper模型 …………58
  - 3.6.2 以命令行的方式运行Whisper ……58
  - 3.6.3 在代码中使用Whisper模型 ………60

**第4章 AI助手开发** ………………………………61
- 4.1 AI助手 ………………………………………61
  - 4.1.1 创建AI助手 …………………………64
  - 4.1.2 函数是如何工作的 …………………65
  - 4.1.3 调用AI助手 …………………………69
  - 4.1.4 通过第三方获取城市气温 …………71
- 4.2 打造播客摘要生成助手 ……………………71
  - 4.2.1 什么是播客摘要生成助手 …………71
  - 4.2.2 创建播客摘要生成助手 ……………73
  - 4.2.3 响应OpenAI的流式返回 …………75
  - 4.2.4 使用助手 ……………………………76
- 4.3 创建HTTP服务器 ……………………………76
  - 4.3.1 引入Express.js ……………………76
  - 4.3.2 实现文件上传 ………………………78
  - 4.3.3 完善路由 ……………………………81
  - 4.3.4 提升代码的健壮性 …………………84
- 4.4 使用代码管理AI助手 ………………………85
  - 4.4.1 引入GitHub Actions ………………86
  - 4.4.2 编写工作流 …………………………87
  - 4.4.3 编写部署脚本 ………………………91
  - 4.4.4 看懂工作流 …………………………93
- 4.5 部署上线 ……………………………………94
  - 4.5.1 创建守护进程 ………………………95
  - 4.5.2 库备服务器 …………………………97
  - 4.5.3 通过GitHub Actions部署上线 …101
  - 4.5.4 验证服务 …………………………103

**第5章 使用Haystack开发AI应用** ……………108
- 5.1 重新认识框架 ……………………………108
  - 5.1.1 为什么需要框架 …………………108
  - 5.1.2 何谓好的框架 ……………………108
  - 5.1.3 也许你不需要框架 ………………109
- 5.2 为什么选择Haystack ……………………110
  - 5.2.1 为什么不推荐LangChain ………112
  - 5.2.2 其他框架 …………………………112
  - 5.2.3 迎接Haystack ……………………115
- 5.3 初试Haystack ……………………………61
  - 5.3.1 基本概念 ……………………………61
  - 5.3.2 初试组件与流水线 …………………64
  - 5.3.3 自定义组件 …………………………69
- 5.4 使用Haystack重构播客助手 ………………71
  - 5.4.1 使用Haystack进行重构 ……………73
  - 5.4.2 使用Gemini替代GPT模型 ………75
- 5.5 启用Haystack日志 …………………………76
- 5.6 启用Haystack追踪 …………………………78
  - 5.6.1 启用追踪 ……………………………81
  - 5.6.2 与OpenTelemetry集成 ……………84
  - 5.6.3 与Langfuse集成 ……………………85

**第6章 RAG应用开发** ……………………………86
- 6.1 初试RAG技术 ………………………………87
  - 6.1.1 使用Chroma实现语义化搜索 ……91
  - 6.1.2 元数据过滤 …………………………93
  - 6.1.3 与OpenAI配合 ……………………95
- 6.2 向量数据库原理 ……………………………97
  - 6.2.1 余弦相似度 ………………………101
  - 6.2.2 文本嵌入 …………………………103
  - 6.2.3 对Chroma进行嵌入配置 ………108
- 6.3 长文本处理 ………………………………108
  - 6.3.1 分割数据 …………………………109
  - 6.3.2 固定大小的分块策略 ……………110
  - 6.3.3 基于文档结构的分块策略 ………112
  - 6.3.4 递归式分块策略 …………………115
- 6.4 使用Haystack实现流水线 ………………61
  - 6.4.1 索引流水线 …………………………64
  - 6.4.2 查询流水线 …………………………69
  - 6.4.3 简化流水线 …………………………71
- 6.5 拓展流水线 …………………………………73
  - 6.5.1 索引数据 ……………………………75
  - 6.5.2 优化数据检索 ………………………76

**第7章 接入第三方AI服务** ……………………184
- 7.1 Hugging Face ……………………………184
  - 7.1.1 注册Hugging Face …………………187
  - 7.1.2 调用Hugging Face推理服务 ……189
  - 7.1.3 与Haystack集成 …………………189
  - 7.1.4 Hugging Face的服务类型 ………190
- 7.2 Together AI ………………………………191
  - 7.2.1 注册Together AI服务 ……………193
  - 7.2.2 访问推理服务 ……………………194
  - 7.2.3 函数调用 …………………………198
- 7.3 Pinecone …………………………………199
  - 7.3.1 注册Pinecone ……………………200
  - 7.3.2 使用Pinecone ……………………207
- 7.4 Cohere ……………………………………208
  - 7.4.1 注册Cohere ………………………209
  - 7.4.2 调用Cohere推理服务 ……………212
  - 7.4.3 在Haystack中使用Cohere模型 …214
- 7.5 Railway ……………………………………214
  - 7.5.1 需要解决的问题 …………………215
  - 7.5.2 使用Railway部署我们的服务 ……220
- 7.6 博客存储流水线 …………………………220
  - 7.6.1 下载文章 …………………………223
  - 7.6.2 组装流水线 ………………………225
  - 7.6.3 部署服务 …………………………228

**第8章 微调模型** …………………………………228
- 8.1 在OpenAI中进行微调 ……………………228
  - 8.1.1 准备训练数据 ……………………229
  - 8.1.2 通过界面进行微调 ………………234
- 8.2 使用Google AI进行微调 …………………234
  - 8.2.1 使用Vertex AI Studio进行微调 …240
  - 8.2.2 通过API进行微调 …………………244

**第9章 智能体开发入门** …………………………244
- 9.1 OpenAI智能体 ……………………………244
  - 9.1.1 第一个简单的智能体 ……………245
  - 9.1.2 任务转移 …………………………246
  - 9.1.3 调用工具 …………………………249
  - 9.1.4 借用智能体对播客摘要生成助手进行重构 ……………………………251
- 9.2 自定义智能体处理流程 …………………255
- 9.3 利用Cohere的Command模型开发智能体 255
  - 9.3.1 准备工作 …………………………258
  - 9.3.2 编写智能体 ………………………262
- 9.4 护栏 ………………………………………262
  - 9.4.1 输入护栏 …………………………264
  - 9.4.2 输出护栏 …………………………265
  - 9.4.3 第三方护栏 ………………………268
- 9.5 模型上下文协议 …………………………268
  - 9.5.1 MCP架构 …………………………269
  - 9.5.2 MCP工具 …………………………272
  - 9.5.3 使用已有的MCP服务器 …………276

**第10章 使用LangGraph构建智能体** …………276
- 10.1 一个简单的LangGraph应用 ……………276
  - 10.1.1 创建图对象 ………………………277
  - 10.1.2 添加节点 …………………………278
  - 10.1.3 stream_mode ……………………279
- 10.2 在LangGraph中使用工具 ………………280
  - 10.2.1 简单的工具调用 …………………280
  - 10.2.2 复杂的工具调用 …………………283
- 10.3 子图机制 …………………………………285
  - 10.3.1 简单子图 …………………………285
  - 10.3.2 参数不兼容的情况 ………………288
  - 10.3.3 使用LangSmith对数据流进行追踪 ……………………………………289
- 10.4 任务转移 …………………………………291
  - 10.4.1 智能体间的任务转移 ……………291
  - 10.4.2 监督者模式 ………………………294
- 10.5 一个复杂的图 ……………………………296
  - 10.5.1 在向量数据库中搜索 ……………298
  - 10.5.2 在网络上搜索 ……………………300
  - 10.5.3 连接图 ……………………………303
- 10.6 添加前端界面 ……………………………305
  - 10.6.1 LangGraph服务 …………………305
  - 10.6.2 前端 ………………………………
- 10.7 实现人机交互 ……………………………
  - 10.7.1 简单的人机交互 …………………
  - 10.7.2 借助CopilotKit实现人机交互 …

## 勒口文案

这是一本面向开发者的AI应用开发实战指南。作者结合自己十多年大型系统的架构设计和开发经验，用传统前后端开发者熟悉的语言，系统梳理OpenAI开发者平台、Gemini、向量数据库、RAG、智能体、MCP、LangGraph等AI应用开发的概念及形态，从0到1开发并部署端到端AI应用。

全书分两条主线。"入门线"利用OpenAI开发者平台和Haystack框架，以低复杂度的代码和精简的技术栈开发并重构多款AI应用，解释AI应用开发的概念与常见模式。"进阶线"引入向量数据库和第三方云服务，讲解如何基于LangGraph构建智能体并添加前端界面，完成个人博客RAG和智能体协作，并进行调试、监控及CI/CD，一次性补齐生产级能力。书中每章都遵循"先跑通、再理解、再替换、再上线"的节奏，先展示结果，再拆解原理。

本书旨在帮助想用AI提升产品竞争力的前后端开发者、需要进行快速概念验证的技术经理与创业者，以及希望将大模型接入现有系统的架构师与运维工程师，用自己熟悉的工具把先进的AI能力转化为可上线、可扩展、可盈利的产品。
```